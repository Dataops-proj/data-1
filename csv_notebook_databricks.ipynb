{"cells": [{"cell_type": "code", "source": ["import hvac \nimport pyspark \nfrom pyspark.sql.types import * \nfrom pyspark.sql.functions import * \nfrom datetime import datetime \nfrom pyspark.sql import SparkSession \nfrom pyspark.sql.functions import col"], "metadata": {"application/vnd.databricks.v1+cell": {"showTitle": false, "cellMetadata": {}, "inputWidgets": {}, "title": "import modules"}}, "outputs": [], "execution_count": 0}, {"cell_type": "code", "source": ["\nspark=SparkSession.builder.appName('DATA-OPS').getOrCreate()\nsc = spark.sparkContext\n\nclient = hvac.Client(url='http://127.0.0.1:8200', token='hvs.sL1Obxm8SuQGR6KnzwUTH8JV')\ns_s3_credentials = client.read('kv/data/data/source_s3_credentials')['data']['data']\naccess_key = s_s3_credentials.get('access_key')\nsecret_key = s_s3_credentials.get('secret_key')\naws_region = 'ap-south-1'\n\nsc._jsc.hadoopConfiguration().set('fs.s3a.access.key', access_key)\nsc._jsc.hadoopConfiguration().set('fs.s3a.secret.key', secret_key)\nsc._jsc.hadoopConfiguration().set('fs.s3a.endpoint', 's3.' + aws_region + '.amazonaws.com')\n\ndf = spark.read.format('csv').options(header='True').load('s3://red-buckets/us-500.csv')"], "metadata": {"application/vnd.databricks.v1+cell": {"showTitle": false, "cellMetadata": {}, "inputWidgets": {}, "title": "Actions"}}, "outputs": [], "execution_count": 0}, {"cell_type": "code", "source": ["\n#Validation-notempty \ndf = df.filter(~col('first_name').isNull()).limit(100)\ndf = df.filter(~col('last_name').isNull()).limit(100)\n\n#Validation-custom \n\nif df.filter(df['company_name'].rlike('@')).count() > 0: \n      raise ValueError('Custom validation failed. Stopping processing.')  \n\nelif df.filter(df['city'].rlike('@')).count() > 0: \n      raise ValueError('Custom validation failed. Stopping processing.')  \n\nelif df.filter(df['address'].rlike('@')).count() > 0: \n      raise ValueError('Custom validation failed. Stopping processing.')  \n\n#Transformations\nelse:\n   df = df.withColumn('first_name', df['first_name'].cast('string'))\n   df = df.withColumn('last_name', df['last_name'].cast('string'))\n   df = df.withColumn('company_name', df['company_name'].cast('string'))\n   df = df.withColumn('address', df['address'].cast('string'))\n   df = df.withColumn('city', df['city'].cast('string'))\n   df = df.withColumn('FULLNAME', concat(\"first_name\", \"last_name\"))"], "metadata": {"application/vnd.databricks.v1+cell": {"showTitle": false, "cellMetadata": {}, "inputWidgets": {}, "title": "Actions"}}, "outputs": [], "execution_count": 0}, {"cell_type": "code", "source": ["\ndf.write.mode('overwriteasdwseff').format('csv').save('s3a://blue-buckets/two/')"], "metadata": {"application/vnd.databricks.v1+cell": {"showTitle": false, "cellMetadata": {}, "inputWidgets": {}, "title": "Actions"}}, "outputs": [], "execution_count": 0}], "metadata": {"application/vnd.databricks.v1+notebook": {"notebookName": "csv_notebook", "dashboards": [], "notebookMetadata": {"pythonIndentUnit": 4}, "language": "python", "widgets": {}}}, "nbformat": 4, "nbformat_minor": 0}