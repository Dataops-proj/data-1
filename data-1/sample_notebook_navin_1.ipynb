{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"showTitle":false,"title":"import modules"}},"outputs":[],"source":["import pyspark \n","from pyspark.sql.types import * \n","from pyspark.sql.functions import * \n","from datetime import datetime \n","from pyspark.sql import SparkSession \n","from pyspark.sql.functions import col"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"showTitle":false,"title":"Actions"}},"outputs":[],"source":["\n","spark=SparkSession.builder.appName('DATA-OPS').getOrCreate()\n","sc = spark.sparkContext\n","\n","access_key='AKIA2JHMCXOOXG3XPKN4'\n","secret_key='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'\n","aws_region = 'ap-south-1'\n","sc._jsc.hadoopConfiguration().set('fs.s3a.access.key', access_key)\n","sc._jsc.hadoopConfiguration().set('fs.s3a.secret.key', secret_key)\n","sc._jsc.hadoopConfiguration().set('fs.s3a.endpoint', 's3.' + aws_region + '.amazonaws.com')\n","df = spark.read.format('csv').options(header='True').load('s3://surendrabucket4/us-500.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"showTitle":false,"title":"Actions"}},"outputs":[],"source":["\n","#Validation-notempty \n","# df = df.filter(~col('first_name').isNull()).limit(100)\n","# df = df.filter(~col('last_name').isNull()).limit(100)\n","\n","# #Validation-custom \n","\n","# if df.filter(df['company_name'].rlike('@')).count() > 0: \n","#       raise ValueError('Custom validation failed. Stopping processing.')  \n","\n","# elif df.filter(df['city'].rlike('@')).count() > 0: \n","#       raise ValueError('Custom validation failed. Stopping processing.')  \n","\n","# elif df.filter(df['address'].rlike('@')).count() > 0: \n","#       raise ValueError('Custom validation failed. Stopping processing.')  \n","\n","# #Transformations\n","# else:\n","#    df = df.withColumn('first_name', df['first_name'].cast('string'))\n","#    df = df.withColumn('last_name', df['last_name'].cast('string'))\n","#    df = df.withColumn('company_name', df['company_name'].cast('string'))\n","#    df = df.withColumn('address', df['address'].cast('string'))\n","#    df = df.withColumn('city', df['city'].cast('string'))\n","#    df = df.withColumn('FULLNAME', concat(\"first_name\", \"last_name\", \"address\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"showTitle":false,"title":"Actions"}},"outputs":[],"source":["\n","df.write.format('csv').save('s3a://surendrabucket3/Dataops234/navin1')"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"csv_notebook","widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
